import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV

top_features = [
    'PRODUCTO_HOMOLOGADO', 'CFM_FIJO_TOTAL', 'SERVICIOS_FIJO_TOTAL', 'CFM_MOVIL_TOTAL',
    'PATRIMONIO', 'PERSONAL', 'ANTIGUEDAD_EMPRESA'
]

def preparar_datos(df_nits, df_base):
    """
    Cruza los NITs del DataFrame df_nits con la base completa df_base para extraer 
    la informaci√≥n correspondiente a esos NITs.

    Par√°metros:
    - df_nits: DataFrame con columna 'IDENTIFICACION' (solo NITs).
    - df_base: DataFrame con la columna 'IDENTIFICACION' y m√°s datos.

    Retorna:
    - DataFrame con las filas completas de df_base correspondientes a los NITs dados.
    """

    # Asegurar que las columnas est√©n en may√∫sculas
    df_nits.columns = df_nits.columns.str.upper()
    df_base.columns = df_base.columns.str.upper()

    # Filtrar base por los NITs
    df_resultado = df_base[df_base['IDENTIFICACION'].isin(df_nits['IDENTIFICACION'])].copy()
    df_resultado = df_resultado[top_features]
    
    #creamos columna target = 1
    df_resultado['TARGET'] = 1
    #Modificamos columna producto_homologado a producto_a_buscar
    df_resultado['PRODUCTO_HOMOLOGADO'] = "PRODUCTO_A_BUSCAR"
    
    return df_resultado

def muestreo_estratificado(df_resultado, df_base):
    """
    Realiza un muestreo estratificado de la base principal seg√∫n la columna 'SECTOR',
    que se reconstruye a partir de variables one-hot codificadas.
    
    El tama√±o del muestreo es 3 veces el n√∫mero de registros de df_resultado.

    Par√°metros:
    - df_resultado: DataFrame de entrada con los NITs cruzados (filtrado).
    - df_base: DataFrame completo con columnas one-hot de sector.

    Retorna:
    - DataFrame con la muestra estratificada.
    """

    df_base = df_base.copy()

    # Asegurarse de que las columnas est√©n en may√∫sculas
    df_base.columns = df_base.columns.str.upper()

    # Definir las columnas de sector (one-hot)
    cols_sector = ['SEGMENTO_COMERCIAL_GOBIERNO', 'SEGMENTO_COMERCIAL_GRANDES', 'SEGMENTO_COMERCIAL_NEGOCIOS']

    # Reconstruir variable 'SECTOR'
    df_base['SECTOR'] = df_base[cols_sector].idxmax(axis=1).str.replace('SEGMENTO_COMERCIAL_', '', regex=False)

    # Tama√±o deseado: 3 veces el tama√±o del df_resultado
    n_total = 3 * len(df_resultado)

    # Calcular proporciones
    proporciones = df_base['SECTOR'].value_counts(normalize=True)

    # Calcular cu√°ntas muestras por clase
    muestras_por_clase = (proporciones * n_total).round().astype(int)
 
    # Hacer el muestreo estratificado
    df_muestra = (
    df_base.groupby('SECTOR', group_keys=False)
           .apply(lambda x: x.sample(
               n=min(muestras_por_clase.get(x.name, 0), len(x)),
               random_state=42
           ))
    )
    
    df_muestra = df_muestra[top_features]
    
    #Creamos columna target = 0
    df_muestra['TARGET'] = 0
    #Modificamos columna producto_homologado a no_producto_a_buscar
    df_muestra['PRODUCTO_HOMOLOGADO'] = "NO_PRODUCTO_A_BUSCAR"
    return df_muestra.reset_index(drop=True)


def preparar_datos_modelo(df_targets, df_targetn, test_size=0.2, random_state=42):
    """
    Une dos dataframes, separa X (features) e y (target), y los divide en entrenamiento y prueba.
    
    Retorna:
    - X_train, X_test, y_train, y_test
    """
    df_modelo = pd.concat([df_targets, df_targetn], ignore_index=True)

    # Separar caracter√≠sticas y etiqueta
    X = df_modelo.drop(columns=['PRODUCTO_HOMOLOGADO', 'TARGET'])
    y = df_modelo['TARGET']

    # Dividir los datos
    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)

def entrenar_modelo_basico(X_train, y_train, X_test, y_test):
    """
    Entrena un modelo RandomForest b√°sico y muestra m√©tricas de desempe√±o.
    
    Retorna:
    - modelo entrenado
    """
    model = RandomForestClassifier(class_weight='balanced', random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    y_train_pred = model.predict(X_train)

    print("‚úÖ Modelo b√°sico entrenado\n")
    print("üîç Matriz de confusi√≥n:\n", confusion_matrix(y_test, y_pred))
    print("\nüìã Reporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))
    print(f"\nüéØ Accuracy entrenamiento: {accuracy_score(y_train, y_train_pred):.2f}")
    print(f"üß™ Accuracy test/validaci√≥n: {accuracy_score(y_test, y_pred):.2f}")

    return model


def ajustar_random_forest(X_train, y_train, X_test, y_test, cv=5, n_estimators=100):
    """
    Realiza b√∫squeda de hiperpar√°metros con GridSearchCV sobre RandomForest.
    
    Retorna:
    - mejor modelo encontrado
    """
    param_grid = {
        'max_depth': [3, 5, 10, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', None]
    }

    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)

    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        cv=cv,
        scoring='accuracy',
        n_jobs=-1
    )
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_

    return best_model
def aplicar_modelo(df_nits, df_base, modelo):
    """
    Aplica un modelo entrenado al subconjunto de df_base que no est√° en df_nits,
    usando √∫nicamente las columnas usadas en entrenamiento, pero devolviendo todas las columnas originales.

    Par√°metros:
    - df_nits: DataFrame con columna 'IDENTIFICACION' (NITs ya utilizados).
    - df_base: DataFrame completo con todas las empresas.
    - modelo: Modelo entrenado.
    - feature_cols: Lista de columnas con las que fue entrenado el modelo.

    Retorna:
    - DataFrame con todas las columnas originales + predicci√≥n y probabilidad.
    """

    df_nits = df_nits.copy()
    df_base = df_base.copy()
    df_nits.columns = df_nits.columns.str.upper()
    df_base.columns = df_base.columns.str.upper()

    # Filtrar registros no presentes en df_nits
    df_restante = df_base[~df_base['IDENTIFICACION'].isin(df_nits['IDENTIFICACION'])].copy()

    # Validar columnas de entrada para predicci√≥n
    X_restante = df_restante[top_features].copy()
    # Eliminar la columna 'PRODUCTO_HOMOLOGADO' si existe
    if 'PRODUCTO_HOMOLOGADO' in X_restante.columns:
        X_restante.drop(columns=['PRODUCTO_HOMOLOGADO'], inplace=True)
    # Realizar predicciones
    df_restante['PROBABILIDAD'] = modelo.predict_proba(X_restante)[:, 1]

    return df_restante

def modelo_principal_rentabilizar(base_secundaria=None, base_principal=None):
    df_base_secundaria = preparar_datos(base_secundaria, base_principal)
    df_muestra_base_principal = muestreo_estratificado(df_resultado=df_base_secundaria, df_base=base_principal)
    X_train, X_test, y_train, y_test = preparar_datos_modelo(df_base_secundaria, df_muestra_base_principal)
    modelo_ajustado = ajustar_random_forest(X_train, y_train, X_test, y_test)
    df_resultado = aplicar_modelo(df_nits=base_secundaria, df_base=base_principal, modelo=modelo_ajustado)
    df_resultado = df_resultado.sort_values(by='PROBABILIDAD', ascending=False).head(8000)
    df_resultado = df_resultado.rename(columns={"PROBABILIDAD": "DISTANCIA"})
    df_resultado["DISTANCIA"] = [round(0.1 * (i + 1), 1) for i in range(len(df_resultado))]

    return df_resultado
